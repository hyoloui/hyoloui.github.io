---
sidebar_position: 6
title: 사이킷런을 통한 머신러닝 2
description: 사이킷런(Scikit-learn)을 활용한 머신러닝 핵심 원리 및 실습 가이드
---

## 1. Executive Summary: 머신러닝 모델링의 핵심 요약

사이킷런(Scikit-learn)은 파이썬 기반의 머신러닝 라이브러리로,<br/>
복잡한 알고리즘을 일관되고 직관적인 API로 제공하여 데이터 분석가와 개발자에게 강력한 도구가 됩니다.

데이터 준비부터 모델 학습, 평가에 이르는 표준화된 워크플로우를 익히고,<br/>
여러 분류 모델의 특성과 적용 사례를 심층적으로 분석함으로써 머신러닝 모델링의 핵심 원리를 실질적으로 이해하는 것을 목표로 합니다.

### 일상 속 예시로 개념 설명

우리가 매일 사용하는 이메일 서비스는 수신된 메일이 '스팸'인지 '정상'인지를 자동으로 분류합니다.<br/>
또한, 온라인 쇼핑몰은 우리의 구매 이력을 분석하여 좋아할 만한 상품을 추천해 줍니다.

이처럼 주어진 데이터를 바탕으로 특정 규칙을 학습하여 새로운 데이터에 대한 결과를 예측하거나 분류하는 것이 바로 머신러닝의 핵심 개념, 특히 '분류(Classification)'의 본질입니다.

이러한 문제들은 사이킷런과 같은 도구를 통해 체계적으로 해결될 수 있습니다.<br/>
사이킷런은 데이터의 특성을 파악하고, 적절한 알고리즘을 선택하여 학습시킨 후, 그 성능을 객관적으로 평가하는 일련의 과정을 표준화된 기능으로 제공합니다.

---

## 2. 머신러닝 모델링의 표준 절차

머신러닝 프로젝트의 성공은 체계적인 접근 방식에 달려 있습니다. 어떤 데이터를 사용하든, 어떤 알고리즘을 선택하든 대부분의 머신러닝 프로젝트는 공통적인 작업 흐름을 따릅니다. 사이킷런은 이러한 표준 절차를 매우 효율적으로 수행할 수 있도록 설계되었습니다. Iris, MNIST 데이터셋 예제에서 공통적으로 발견되는 이 표준화된 워크플로우는 모델의 신뢰성을 확보하고 재현 가능한 결과를 만드는 데 필수적입니다.

### 핵심 5단계 워크플로우 분석

### 1단계: 라이브러리 및 데이터 로딩

- 목적: 분석에 필요한 도구와 데이터를 준비하는 단계입니다. 파이썬 라이브러리(sklearn, matplotlib 등)를 가져오고, load_iris()와 같은 내장 함수를 사용하여 분석할 데이터셋을 메모리에 로드합니다. 이는 모든 분석의 출발점입니다.

### 2단계: 데이터 분할 (Train/Test Split)

- 목적: 모델의 일반화 성능을 객관적으로 평가하기 위해 전체 데이터를 학습용(Train)과 테스트용(Test)으로 분리합니다. train_test_split 함수는 이 과정을 자동화합니다. 이는 마치 시험을 준비하는 것과 같습니다. 모델은 학습 데이터(교과서)로 패턴을 '공부'하지만, 모델의 진짜 실력은 한 번도 본 적 없는 테스트 데이터(시험 문제)로 평가됩니다. 학습 데이터만 암기한 모델은 이 새로운 시험에서 실패하게 되는데, 이러한 현상을 '과적합(overfitting)'이라고 합니다. 소스에서 test_size=0.2로 설정한 것은 전체 데이터의 20%를 테스트용으로, 나머지 80%를 학습용으로 사용하겠다는 의미입니다.

### 3단계: 모델 선택 및 학습

- 목적: 해결하고자 하는 문제에 적합한 머신러닝 모델(예: KNeighborsClassifier)을 선택하고, 학습용 데이터를 사용하여 모델을 훈련시키는 과정입니다. .fit(x_train, y_train) 메소드는 모델이 학습 데이터(x_train)와 해당 정답(y_train) 사이의 관계를 학습하도록 명령하는 핵심적인 역할을 합니다.

### 4단계: 예측

- 목적: 학습이 완료된 모델을 사용하여 새로운 데이터에 대한 결과를 예측합니다. .predict(x_test) 메소드는 학습 과정에서 사용되지 않은 테스트 데이터(x_test)를 입력으로 받아, 모델이 학습한 패턴을 기반으로 예측값(y_predic)을 생성합니다.

### 5단계: 평가

- 목적: 모델의 성능을 정량적으로 측정하는 마지막 단계입니다. metrics.accuracy_score와 같은 평가 지표는 모델의 예측값(y_predic)과 실제 정답(y_test)을 비교하여 정확도를 계산합니다. 이 점수를 통해 모델이 얼마나 신뢰할 수 있는지 객관적으로 판단할 수 있습니다.

이 표준화된 절차는 다양한 알고리즘과 데이터셋에 일관되게 적용될 수 있다는 점에서 매우 강력합니다. 다음 섹션에서는 알고리즘의 특성을 시각적으로 이해하는 데 도움이 되는 합성 데이터 생성 방법을 살펴보겠습니다.

---

## 3. 데이터 유형의 시각적 이해: 합성 데이터셋 생성

실제 데이터를 다루기 전에, 특정 구조를 가진 가상의 데이터, 즉 합성 데이터셋을 사용하면 머신러닝 알고리즘의 작동 원리와 장단점을 명확하게 파악할 수 있습니다. 사이킷런은 다양한 형태의 데이터 분포를 생성하는 함수를 제공하여, 여러 시나리오에서 알고리즘의 성능을 테스트하고 시각적으로 이해하는 데 도움을 줍니다.

### 합성 데이터 생성 함수 분석

- `make_classification` 이 함수는 선형적으로 구분 가능한 데이터 클러스터를 생성하는 데 주로 사용됩니다. 로지스틱 회귀나 서포트 벡터 머신(SVM)과 같은 선형 기반 분류 모델의 성능을 테스트하고 결정 경계(decision boundary)를 시각화하는 데 유용합니다.
- `make_blobs` 함수는 여러 개의 뚜렷한 군집(blob) 형태의 데이터를 생성합니다. 각 군집은 가우시안 분포를 따르며, K-평균(K-Means)과 같은 군집화(Clustering) 알고리즘이 데이터 포인트를 올바르게 그룹화하는지 테스트하는 데 이상적입니다.
- `make_moons` 이 함수는 이름처럼 초승달 모양으로 비선형적인 경계를 가진 두 개의 데이터 그룹을 생성합니다. 단순한 직선으로는 두 그룹을 나눌 수 없으므로, 커널 SVM이나 결정 트리 기반의 앙상블 모델과 같이 비선형적 관계를 학습할 수 있는 알고리즘의 성능을 평가하는 데 매우 효과적입니다.
- `make_gaussian_quantiles` 이 함수는 여러 개의 가우시안 분포를 중첩시켜 복잡한 형태의 데이터 분포를 생성합니다. 각 클래스는 동심원 형태를 띠게 되며, 이는 매우 복잡하고 미묘한 데이터 패턴을 모델이 얼마나 잘 학습하는지 테스트하는 데 사용됩니다.

이러한 합성 데이터셋을 통해 알고리즘의 이론적 특성을 파악했다면,
이제 실제 데이터셋에 다양한 모델을 직접 적용하여 그 성능을 비교 분석해 볼 차례입니다.

---

## 4. 핵심 분류 모델 비교 분석: Iris 데이터셋 활용

동일한 Iris 데이터셋에 여러 머신러닝 알고리즘을 적용해 보면 각 모델의 고유한 접근 방식과 결과를 비교할 수 있습니다.
사이킷런의 가장 큰 장점 중 하나는 모델의 종류가 바뀌더라도 .fit(), .predict()와 같은 핵심 메소드 이름과 사용법이 동일하다는 점입니다.
이러한 일관된 API 덕분에 다양한 모델을 빠르고 쉽게 실험하고 비교하는 것이 가능합니다.

먼저, 모든 모델에 공통적으로 사용될 데이터 로딩 및 분할 코드를 실행합니다.

# 공통 데이터 준비 단계

```python
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

# 1. 데이터 로딩

data = load_iris()
x = data.data
y = data.target

# 2. 데이터 분할 (학습용 80%, 테스트용 20%)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

```

이제 위에서 준비된 x_train, y_train 데이터를 사용하여 다양한 모델을 학습시키고 x_test로 예측을 수행해 보겠습니다.
각 모델별로 달라지는 부분은 모델을 불러오고 객체를 생성하는 단 두 줄의 코드뿐입니다.

### 4.1 Logistic Regression

로지스틱 회귀는 이름과 달리 대표적인 분류 알고리즘입니다. 데이터가 특정 클래스에 속할 확률을 계산하기 위해 선형 방정식의 결과를 시그모이드(Sigmoid) 함수에 통과시킨 후, 그 확률값을 기반으로 분류를 수행합니다.

참고: solver='liblinear' 파라미터는 호환성을 보장하고 경고 메시지를 피하기 위해 명시적으로 지정합니다. 최신 Scikit-learn 버전에서는 기본 solver가 변경되었으며, liblinear는 Iris와 같은 작은 데이터셋에 효과적인 선택지입니다.

```python
# 모델 불러오기 및 생성

from sklearn.linear_model import LogisticRegression
model = LogisticRegression(solver='liblinear')

# 모델 학습 및 예측 (공통 워크플로우)

model.fit(x_train, y_train)
pre = model.predict(x_test)

```

### 4.2 K-Nearest Neighbors (KNN)

KNN은 명시적인 학습 함수를 만드는 대신, 훈련 데이터를 모두 저장하는 '인스턴스 기반' 학습 모델입니다.
새로운 데이터가 들어오면, 가장 가까운 K개의 훈련 데이터(이웃)를 찾아 다수결 투표를 통해 클래스를 결정합니다.

직관적이고 데이터 분포에 대한 가정이 필요 없다는 장점이 있지만, 예측 시 모든 훈련 데이터와의 거리를 계산해야 하므로 데이터가 클 경우 계산 비용이 높을 수 있습니다.

```python
# 모델 불러오기 및 생성

from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=3)

# 모델 학습 및 예측 (공통 워크플로우)

model.fit(x_train, y_train)
pre = model.predict(x_test)

```

### 4.3 Naive Bayes

나이브 베이즈 분류기는 베이즈 정리에 기반한 확률적 모델입니다.
모든 특성(feature)이 서로 독립적이라는 '순진한(naive)' 가정을 전제로, 특정 클래스에 속할 조건부 확률을 계산하여 가장 확률이 높은 클래스로 분류합니다.

이 가정 덕분에 계산이 매우 빠르고 텍스트 분류와 같은 문제에서 좋은 성능을 보입니다.

```python
# 모델 불러오기 및 생성

from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()

# 모델 학습 및 예측 (공통 워크플로우)

model.fit(x_train, y_train)
pre = model.predict(x_test)

```

### 4.4 Decision Tree

결정 트리는 데이터를 특정 기준(질문)에 따라 반복적으로 분할하여 'if-then' 규칙의 집합으로 표현하는 나무 구조의 모델을 만듭니다.<br/>
모델의 의사결정 과정을 시각적으로 이해하기 쉬워 해석력이 매우 높다는 것이 가장 큰 장점입니다.

```python
# 모델 불러오기 및 생성

from sklearn import tree
model = tree.DecisionTreeClassifier()

# 모델 학습 및 예측 (공통 워크플로우)

model.fit(x_train, y_train)
pre = model.predict(x_test)

```

### 4.5 Support Vector Machine (SVM)

SVM은 각 클래스를 가장 잘 구분할 수 있는 최적의 경계(hyperplane)를 찾는 알고리즘입니다.<br/>
이때, 단순히 클래스를 나누는 것을 넘어 각 클래스의 가장 가까운 데이터 포인트(서포트 벡터)와 경계 사이의 거리,

즉 마진(margin)을 최대로 만드는 경계를 찾아 일반화 성능을 높이는 것을 목표로 합니다.

```python
# 모델 불러오기 및 생성

from sklearn.svm import SVC
model = SVC()

# 모델 학습 및 예측 (공통 워크플로우)

model.fit(x_train, y_train)
pre = model.predict(x_test)
```

### 4.6 Random Forest

랜덤 포레스트는 '집단 지성'의 원리를 활용하는 앙상블 기법입니다.<br/>
여러 개의 결정 트리를 독립적으로 학습시킨 후, 각 트리의 예측 결과를 종합(다수결 투표)하여 최종 결정을 내립니다.

이 과정을 통해 단일 결정 트리가 가질 수 있는 과적합(overfitting) 위험을 줄이고, 더 안정적이고 정확한 예측 성능을 얻을 수 있습니다.

```python
# 모델 불러오기 및 생성

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(max_depth=7, random_state=0)

# 모델 학습 및 예측 (공통 워크플로우)

model.fit(x_train, y_train)
pre = model.predict(x_test)

```

이처럼 표준화된 데이터셋을 통해 각 모델의 기본적인 적용법을 익혔으니, 이제 더 복잡하고 현실적인 데이터셋을 다루는 사례를 통해 응용력을 심화시켜 보겠습니다.

---

## 5. 실제 데이터 적용 사례 심층 분석

이론적인 모델링을 넘어 실제 데이터를 다룰 때는 데이터 형태 변환, 결측치 처리, 이상치 탐지 등 고유한 과제들이 발생합니다. 이 섹션에서는 MNIST 손글씨, 유방암 진단, 피마 인디언 당뇨병 데이터를 통해 이러한 실전 과제들을 어떻게 해결하는지 구체적인 사례를 중심으로 분석합니다.

### 5.1 이미지 분류: MNIST 손글씨 숫자 인식

- 과제 정의: 이 과제는 8x8 픽셀 크기의 손으로 쓴 숫자 이미지(총 1,797개)를 보고, 해당 이미지가 0부터 9까지의 숫자 중 무엇인지를 정확하게 분류하는 문제입니다.
- 핵심 전처리 과정 분석: 모델은 일반적으로 평평한 1차원 배열 형태의 특징(feature)을 입력으로 요구합니다. reshape(-1, 64) 명령어는 8x8 픽셀의 2차원 그리드를 64개의 픽셀 값으로 이루어진 1차원 벡터로 '평탄화(flattening)'하는 역할을 합니다. 이는 KNN과 같은 대부분의 표준 분류기가 이미지의 2차원 공간 관계를 본질적으로 이해하지 못하고 각 픽셀을 독립적인 특징으로 취급하기 때문에 반드시 필요한 전처리 단계입니다.
- 모델 적용 및 평가: 데이터 전처리가 완료된 후, 앞서 살펴본 표준 워크플로우에 따라 데이터를 학습용과 테스트용으로 분할합니다. 그 다음, KNN 모델(KNeighborsClassifier)을 선택하여 학습 데이터로 훈련시키고, 테스트 데이터에 대한 예측을 수행합니다. 마지막으로 accuracy_score를 사용하여 모델이 얼마나 정확하게 손글씨 숫자를 인식했는지 성능을 측정합니다.

### 5.2 의료 진단: 위스콘신 유방암 데이터 분류

- 과제 정의: 이 과제는 종양의 다양한 측정치(30개 독립변수)를 바탕으로 해당 종양이 악성(malignant)인지 양성(benign)인지를 분류하는 대표적인 이진 분류(binary classification) 문제입니다.
- 데이터 특성 요약:
  - 데이터 수: 569개 관측치 (음성 212개, 양성 357개)
  - 독립 변수(Features): 30개
  - 종속 변수(Target): 0(음성) 또는 1(양성)
- 모델 적용: 이 문제는 데이터 특성을 기반으로 두 가지 클래스 중 하나로 분류하는 것이므로 로지스틱 회귀(LogisticRegression)가 효과적인 선택이 될 수 있습니다. 데이터를 학습/테스트용으로 분할한 뒤, 로지스틱 회귀 모델을 학습시키고 예측 정확도를 평가하는 표준 절차를 동일하게 따릅니다.

### 5.3 예측 분석 및 데이터 전처리: 피마 인디언 당뇨병 예측

- 과제 정의: 이 사례는 개인의 임신 횟수, 혈압, 나이 등 8가지 변수를 기반으로 당뇨병 발병 여부를 예측하는 과제입니다. 특히 이 사례는 모델링 이전에 수행되는 데이터 탐색과 전처리가 모델 성능에 얼마나 결정적인 영향을 미치는지 잘 보여줍니다.
- 데이터 탐색 및 시각화의 중요성: seaborn 라이브러리를 사용한 시각화는 데이터에 숨겨진 패턴과 인사이트를 발견하는 데 매우 중요합니다. 예를 들어, boxplot을 통해 '당뇨병 여부에 따른 임신 횟수'나 'BMI'의 분포 차이를 시각적으로 확인하거나, barplot으로 '나이대별 발병률'의 경향을 파악할 수 있습니다. 이러한 탐색적 데이터 분석(EDA)은 모델링 전략을 수립하는 데 핵심적인 단서를 제공합니다.
- 결측치 및 이상치 처리 전략: 실제 데이터는 종종 불완전합니다. 신뢰성 있는 모델을 만들기 위해서는 데이터의 품질을 높이는 과정이 필수적입니다.
  1. 결측치 확인: df.isnull().sum() 코드를 사용하여 각 변수에 누락된 값이 있는지 확인합니다.
  2. 이상치(Outlier) 탐지 및 제거: 데이터의 평균과 표준편차를 계산하여 정상 범위를 크게 벗어나는 값(예: 평균 + 3 \* 표준편차 이상)을 이상치로 간주하고 제거하는 전략을 사용합니다. 이는 모델이 비정상적인 데이터에 의해 왜곡되는 것을 방지하는 결정적인 단계입니다. 이 전략은 데이터가 정규 분포를 따른다는 가정에 기반한 일반적인 출발점입니다. 다만, 데이터 분포가 한쪽으로 치우쳐 있거나 금융 거래처럼 극단적인 값이 합법적인 경우에는 더 정교한 방법이 필요할 수 있습니다. 이 데이터셋에서는 통계적 변칙을 실용적으로 제거하는 방법으로 사용됩니다.
- 종합적 워크플로우: 이 사례는 단순히 모델을 적용하고 끝나는 것이 아니라, 데이터 탐색 및 시각화 → 분석을 통한 인사이트 도출 → 결측치 및 이상치 전처리 → 모델 학습 → 성능 평가로 이어지는 종합적인 데이터 분석 프로젝트의 전형적인 워크플로우를 보여줍니다.

---

## 6. 결론: 주요 학습 내용 종합

이 문서는 사이킷런을 활용한 머신러닝 모델링의 핵심 원리와 실제 적용 과정을 체계적으로 살펴보았습니다. 합성 데이터를 통한 알고리즘의 시각적 이해부터 표준화된 데이터셋에서의 모델 비교, 그리고 전처리가 중요한 실제 데이터 분석에 이르기까지, 성공적인 머신러닝 프로젝트를 위한 핵심 요소들을 다루었습니다.

### 핵심 교훈 도출

1. 일관성과 효율성: 사이킷런이 제공하는 .fit(), .predict()와 같은 일관된 API 덕분에 로지스틱 회귀, SVM, 랜덤 포레스트 등 다양한 머신러닝 알고리즘을 마치 동일한 도구를 사용하듯 쉽고 빠르게 실험하고 적용할 수 있습니다. 이는 모델링의 효율성을 극대화합니다.
2. 체계적 접근의 힘: 성공적인 머신러닝 프로젝트는 데이터 로딩 → 데이터 분할 → 모델 학습 → 예측 → 평가라는 표준화된 워크플로우를 따릅니다. 이 체계적인 접근 방식은 모델의 성능을 객관적으로 검증하고, 재현 가능한 결과를 보장하는 기반이 됩니다.
3. 모델 성능은 데이터 전처리 과정에서 결정된다: 피마 인디언 당뇨병 예측 사례에서 명확히 확인했듯이, 실제 데이터를 다룰 때는 어떤 모델을 선택하느냐 만큼이나 데이터 자체의 품질이 중요합니다. 데이터 탐색 및 시각화를 통한 인사이트 확보, 그리고 결측치 및 이상치 처리와 같은 전처리 과정은 모델의 신뢰성과 최종 성능에 결정적인 영향을 미칩니다. 피마 인디언 사례는 정교한 알고리즘만으로는 저품질 데이터를 구원할 수 없음을 증명합니다. 궁극적으로, 실제 머신러닝 프로젝트에서 가장 영향력 있는 작업은 .fit() 메소드가 호출되기 전에 이미 이루어지는 경우가 많습니다.
